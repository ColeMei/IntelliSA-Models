# Encoder Model Configuration (CodeT5p-2B)
model_name: "Salesforce/codet5p-2b"
max_length: 512

# Resource-aware defaults for 2B parameters on a single A100
batch_size: 1
learning_rate: 1e-5
num_epochs: 3
warmup_steps: 200
eval_steps: 50
save_steps: 100

# Additional training knobs consumed by encoder path
weight_decay: 0.01
gradient_accumulation_steps: 8
gradient_checkpointing: true
early_stopping_patience: 3
early_stopping_min_delta: 0.001
fp16: true
dataloader_pin_memory: true

# Data paths (will be overridden by CLI args)
train_path: "data/processed/chef_train.jsonl"
val_path: "data/processed/chef_val.jsonl"
output_dir: "models/encoder"

# Training arguments
evaluation_strategy: "steps"
save_strategy: "steps"
logging_steps: 10
load_best_model_at_end: true
metric_for_best_model: "f1"
greater_is_better: true
